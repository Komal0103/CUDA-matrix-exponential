{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Komal0103/CUDA-matrix-exponential/blob/main/matrix-exponential.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5UrLqlvyzhO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "# from scipy.linalg._misc import norm\n",
        "import cupy as cp\n",
        "from cupy.linalg import norm\n",
        "import math\n",
        "# import ipdb\n",
        "\n",
        "import numba\n",
        "from numba import cuda\n",
        "import pdb\n",
        "from pdb import set_trace"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit(device=True, inline=True)\n",
        "def matmul(a, b, c, m, n, k):\n",
        "  # implement tiling here\n",
        "  row = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
        "  col = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "  if (row<m and col<k):\n",
        "    sum=0\n",
        "    for i in range(n):\n",
        "      # sum=0\n",
        "      A=a[row*n+i]\n",
        "      B=b[col+i*k]\n",
        "      sum=sum+A*B\n",
        "    c[row*k+col]=sum\n",
        "\n",
        "@cuda.jit(device=True, inline=True)\n",
        "def addMatrices(a, b, c, n, threadId):\n",
        "  row = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
        "  col = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "  if (row<n and col<n):\n",
        "    for i in range(n):\n",
        "      c[row*n+col]=a[row*n+col]+b[row*n+col]\n",
        "  # if threadId<(n**2):\n",
        "    # c[threadId]=a[threadId]+b[threadId]\n",
        "\n",
        "@cuda.jit\n",
        "def squaring(E, eA, S, n):\n",
        "  s=S[0]\n",
        "  for k in range(s):\n",
        "    # a possible problem here\n",
        "    matmul(E, E, eA, n, n, n)\n",
        "    if s>1:\n",
        "      E=eA\n",
        "\n",
        "@cuda.jit\n",
        "def computeA3(a, a2, a3, n):\n",
        "  matmul(a, a2, a3, n, n, n)\n",
        "\n",
        "@cuda.jit\n",
        "def computeA4(a, a2, s, temp, i, E, n):\n",
        "  blockId=cuda.blockIdx.x+cuda.blockIdx.y*cuda.gridDim.x\n",
        "  threadId=blockId * (cuda.blockDim.x * cuda.blockDim.y) + (cuda.threadIdx.y * cuda.blockDim.x) + cuda.threadIdx.x\n",
        "  matmul(a2, s, temp, n, n, n)\n",
        "  if threadId<n*n:\n",
        "    E[threadId]=i[threadId]+a[threadId]+temp[threadId]\n",
        "\n",
        "@cuda.jit\n",
        "def computeA8(a, a2, a4, a8, i, temp, temp2, E, n):\n",
        "  x3=[2/3]\n",
        "  coeff=[1/88*(1+cp.sqrt(177))*x3, 1/352*(1+cp.sqrt(177))*x3, 1, 1, 1/630*(857-58*cp.sqrt(177)),\n",
        "         (-271+29*cp.sqrt(177))/(315*x3), (11*(-1+cp.sqrt(177)))/(1260*x3), (11*(-9+cp.sqrt(177)))/(5040*x3),\n",
        "         -((-89+cp.sqrt(177))/(5040*x3^2))]\n",
        "  # error here-thread idexing issue\n",
        "  # get the absolute grid index of the thread, and then make sure it is less than n*n (total number of elements in the array)\n",
        "  blockId=cuda.blockIdx.x+cuda.blockIdx.y*cuda.gridDim.x\n",
        "  threadId=blockId * (cuda.blockDim.x * cuda.blockDim.y) + (cuda.threadIdx.y * cuda.blockDim.x) + cuda.threadIdx.x\n",
        "  if threadId<n*n:\n",
        "    temp[threadId]=coeff[0]*a[threadId]+coeff[1]*a2[threadId]\n",
        "  matmul(a2, temp, a4, n, n, n)\n",
        "  if threadId<n*n:\n",
        "    temp[threadId]=x3[0]*a2[threadId]+a4\n",
        "    temp2[threadId]=coeff[5]*i[threadId]+coeff[6]*a+coeff[7]*a2[threadId]+coeff[8]*a4\n",
        "  matmul(temp, temp2, a8, n, n, n)\n",
        "  if threadId<n*n:\n",
        "    # TODO: check for missing term\n",
        "    E[threadId]=i[threadId]+a[threadId]+coeff[4]*a2[threadId]+a8[threadId]\n",
        "\n",
        "@cuda.jit\n",
        "def computeA18(a, a2, a3, a6, i, temp1, temp2, temp3, temp4, temp5, temp6, temp7, temp8, temp9, E, coeff, n):\n",
        "  # TODO: consider making an array of a class for all the temporary variables here, inside the kernel, if possible\n",
        "  blockId=cuda.blockIdx.x+cuda.blockIdx.y*cuda.gridDim.x\n",
        "  threadId=blockId * (cuda.blockDim.x * cuda.blockDim.y) + (cuda.threadIdx.y * cuda.blockDim.x) + cuda.threadIdx.x\n",
        "  if threadId<n**2:\n",
        "    a6[threadId]=0\n",
        "    temp1[threadId]=0\n",
        "    temp2[threadId]=0\n",
        "    temp3[threadId]=0\n",
        "    temp4[threadId]=0\n",
        "    temp5[threadId]=0\n",
        "    temp6[threadId]=0\n",
        "    temp7[threadId]=0\n",
        "    temp8[threadId]=0\n",
        "    temp9[threadId]=0\n",
        "  matmul(a3, a3, a6, n, n, n)\n",
        "  if threadId<(n**2):\n",
        "    temp1[threadId]=coeff[1]*a[threadId]+coeff[2]*a2[threadId]+coeff[3]*a3[threadId]\n",
        "    temp2[threadId]=coeff[5]*a[threadId]+coeff[6]*a2[threadId]+coeff[7]*a3[threadId]+coeff[8]*a6[threadId]\n",
        "    temp3[threadId]=coeff[9]*i[threadId]+coeff[10]*a[threadId]+coeff[11]*a2[threadId]+coeff[12]*a3[threadId]+coeff[13]*a6[threadId]\n",
        "    temp4[threadId]=coeff[14]*i[threadId]+coeff[15]*a[threadId]+coeff[16]*a2[threadId]+coeff[17]*a3[threadId]+coeff[18]*a6[threadId]\n",
        "    temp5[threadId]=coeff[21]*a2[threadId]+coeff[22]*a3[threadId]+coeff[23]*a6[threadId]\n",
        "  matmul(temp1, temp5, temp6, n, n, n)\n",
        "  cuda.syncthreads()\n",
        "  addMatrices(temp4, temp6, temp7, n, threadId)\n",
        "  # cuda.syncthreads()\n",
        "  # if threadId<(n**2):\n",
        "    # temp7[threadId]=temp4[threadId]+temp6[threadId]\n",
        "  if threadId<(n**2):\n",
        "    # try to reuse temp6 here\n",
        "    temp9[threadId]=temp3[threadId]+temp7[threadId]\n",
        "  matmul(temp9, temp7, temp8, n, n, n)\n",
        "  cuda.syncthreads()\n",
        "  if threadId<(n**2):\n",
        "    E[threadId]=temp2[threadId]+temp8[threadId]\n",
        "\n",
        "@cuda.jit\n",
        "def computeA12(a, a2, a3, i, temp1, temp2, temp3, temp4, temp5, temp6, temp7, E, coeff, n):\n",
        "  blockId=cuda.blockIdx.x+cuda.blockIdx.y*cuda.gridDim.x\n",
        "  threadId=blockId * (cuda.blockDim.x * cuda.blockDim.y) + (cuda.threadIdx.y * cuda.blockDim.x) + cuda.threadIdx.x\n",
        "  # TODO: check once\n",
        "  if threadId<n*n:\n",
        "    temp1=coeff[0]*i+coeff[4]*a+coeff[8]*a2+coeff[12]*a3\n",
        "    temp2=coeff[1]*i+coeff[5]*a+coeff[9]*a2+coeff[13]*a3\n",
        "    temp3=coeff[2]*i+coeff[6]*a+coeff[10]*a2+coeff[14]*a3\n",
        "    temp4=coeff[3]*i+coeff[7]*a+coeff[11]*a2+coeff[15]*a3\n",
        "    matmul(temp4, temp4, temp5, n, n, n)\n",
        "    if threadId<n*n:\n",
        "      temp6[threadId]=temp3[threadId]+temp5[threadId]\n",
        "    if threadId<n*n:\n",
        "      # attempting to reuse temp5\n",
        "      temp5[threadId]=temp2[threadId]+temp6[threadId]\n",
        "    matmul(temp5, temp6, temp7, n, n, n)\n",
        "    if threadId<n*n:\n",
        "      E[threadId]=temp1[threadId]+temp7[threadId]"
      ],
      "metadata": {
        "id": "osm0N_AUzD1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TaylorAlgorithm(a, degree, n, TILE_SIZE):\n",
        "  # blocks_per_grid=(math.ceil((n-1)/TILE_SIZE)+1, math.ceil((n-1)/TILE_SIZE)+1)\n",
        "  blocks_per_grid=(2, 2)\n",
        "  threads_per_block=(TILE_SIZE, TILE_SIZE)\n",
        "  dev_a=cuda.to_device(a)\n",
        "  if degree>=2:\n",
        "    dev_a2=cuda.device_array([n**2,], dtype=\"complex\")\n",
        "    s=[1]\n",
        "    dev_s=cuda.to_device(s)\n",
        "    # CUDA inlines functions automatically-matmul is a device function\n",
        "    squaring[blocks_per_grid, threads_per_block](dev_a, dev_a2, dev_s, n)\n",
        "    cuda.synchronize()\n",
        "    a2=dev_a2.copy_to_host()\n",
        "  if degree>=8:\n",
        "    dev_a3=cuda.device_array([n**2], dtype=\"complex\")\n",
        "    # matmul is a device function and cannot be called by the host\n",
        "    computeA3[blocks_per_grid, threads_per_block](dev_a, dev_a2, dev_a3, n)\n",
        "    a3=dev_a3.copy_to_host()\n",
        "    cuda.synchronize()\n",
        "  if degree==1:\n",
        "    E=identity(n)+a\n",
        "  elif degree==2:\n",
        "    E=identity(n)+a+a2/2\n",
        "  elif degree==4:\n",
        "    i=identity(n)\n",
        "    dev_i=cuda.to_device(i)\n",
        "    s=identity(n)/2+a/6+a2/24\n",
        "    dev_s=cuda.to_device(s)\n",
        "    dev_temp=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "    dev_E=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "    computeA4[blocks_per_grid, threads_per_block](dev_a, dev_a2, dev_s, dev_temp, dev_i, dev_E, n)\n",
        "    cuda.synchronize()\n",
        "    E=dev_E.copy_to_host()\n",
        "  elif degree==8:\n",
        "    i=identity(n)\n",
        "    I=i.reshape([n*n,])\n",
        "    dev_i=cuda.to_device(I)\n",
        "    dev_a4=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "    dev_a8=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "    temp=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "    temp2=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "    dev_E=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "    computeA8[blocks_per_grid, threads_per_block](dev_a, dev_a2, dev_a4, dev_a8, dev_i, temp, temp2, dev_E, n)\n",
        "    cuda.synchronize()\n",
        "    E=dev_E.copy_to_host()\n",
        "  elif degree==12:\n",
        "    coeff=np.asarray([-0.0186023205146205532243437300433, 4.6, 0.211693118299809442949323323336, 0,-0.00500702322573317730979741843919, 0.992875103538486836140479571505,\n",
        "         0.158224384715726725371768893252, -0.131810610138301840156819349464, -0.573420122960522263905952420789,\n",
        "         -0.132445561052799638845074997454, 0.165635169436727415011171668419, -0.0202785554058925907933568229945,\n",
        "         -0.133399693943892059700768926983, 0.0017299, 0.0107862779315792425026320640108, -0.00675951846863086359778560766482])\n",
        "    dev_coeff=cuda.to_device(coeff)\n",
        "    i=identity(n)\n",
        "    I=i.reshape([n*n,])\n",
        "    dev_i=cuda.to_device(I)\n",
        "    dev_a3=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "    dev_a8=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "    temp1=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "    temp2=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "    temp3=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "    temp4=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "    temp5=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "    temp6=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "    temp7=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "    dev_E=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "    computeA12[blocks_per_grid, threads_per_block](dev_a, dev_a2, dev_a3, dev_i, temp1, temp2, temp3, temp4, temp5, temp6, temp7, dev_E, dev_coeff, n)\n",
        "    cuda.synchronize()\n",
        "    E=dev_E.copy_to_host()\n",
        "  elif degree==18:\n",
        "    # possible problem here-in computeA18\n",
        "    coeff=cp.asarray([0, -0.100365581030144620014614939405, -0.00802924648241156960116919515244, -0.000892138498045729955685466128049, 0,\n",
        "         0.397849749499645076145196, 1.367837784604117199225237068782228242, 0.49828962252538267755685881726227335, -0.0006378981945947233092415500564919,\n",
        "         -10.9676396052962062593517462675368412, 1.68015813878906197182785401724810509, 0.05717798464788655127028717132252481317,\n",
        "         -0.00698210122488052084290466483801553, 0.00003349750170860705383133673406684398, -0.0904316832390810561971468877018349549,\n",
        "         -0.0676404519071381907560079900379707485, 0.0675961301770459646082799195078937, 0.02955525704293155274260691822422312437,\n",
        "         -0.00001391802575160607011247399793437, 0, 0, -0.0923364619367118592764570775143, -0.0169364939002081717191385115723,\n",
        "         -0.0000140086798182036159794363205726])\n",
        "    dev_coeff=cuda.to_device(coeff)\n",
        "    i=identity(n)\n",
        "    I=i.reshape([n**2])\n",
        "    dev_i=cuda.to_device(I)\n",
        "    dev_a6=cuda.device_array([n**2], dtype=\"complex\")\n",
        "    temp1=cuda.device_array([n**2], dtype=\"complex\")\n",
        "    temp2=cuda.device_array([n**2], dtype=\"complex\")\n",
        "    temp3=cuda.device_array([n**2], dtype=\"complex\")\n",
        "    temp4=cuda.device_array([n**2], dtype=\"complex\")\n",
        "    temp5=cuda.device_array([n**2], dtype=\"complex\")\n",
        "    temp6=cuda.device_array([n**2], dtype=\"complex\")\n",
        "    temp7=cuda.device_array([n**2], dtype=\"complex\")\n",
        "    temp8=cuda.device_array([n**2], dtype=\"complex\")\n",
        "    temp9=cuda.device_array([n**2], dtype=\"complex\")\n",
        "    dev_E=cuda.device_array([n**2], dtype=\"complex\")\n",
        "    computeA18[blocks_per_grid, threads_per_block](dev_a, dev_a2, dev_a3, dev_a6, dev_i, temp1, temp2, temp3, temp4, temp5, temp6, temp7, temp8, temp9, dev_E, dev_coeff, n)\n",
        "    cuda.synchronize()\n",
        "    E=dev_E.copy_to_host()\n",
        "    # host_temp4=temp4.copy_to_host()\n",
        "    # print(host_temp4)\n",
        "    # print(\"------------------------------------------------------------------\")\n",
        "    # host_temp6=temp6.copy_to_host()\n",
        "    # print(host_temp6)\n",
        "    # print(\"------------------------------------------------------------------\")\n",
        "    # host_temp7=temp7.copy_to_host()\n",
        "    # print(host_temp7)\n",
        "    # print(\"------------------------------------------------------------------\")\n",
        "    # host_temp3=temp3.copy_to_host()\n",
        "    # print(host_temp3)\n",
        "    # print(\"------------------------------------------------------------------\")\n",
        "    # host_temp9=temp9.copy_to_host()\n",
        "    # print(host_temp9)\n",
        "    # print(\"------------------------------------------------------------------\")\n",
        "\n",
        "    return E"
      ],
      "metadata": {
        "id": "IkaS8abQzPb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identity(n):\n",
        "    ident=np.zeros([n,n], dtype=\"complex\")\n",
        "    for row in range(n):\n",
        "        for column in range(n):\n",
        "            if (row==column):\n",
        "                ident[row][column]=1\n",
        "    return ident\n",
        "\n",
        "def exponential(a, n, TILE_SIZE):\n",
        "    start=time.perf_counter()\n",
        "    # converting to 1D array for matrix multiplication\n",
        "    A=a.reshape([n*n,])\n",
        "    anorm=cp.linalg.norm(a, 1)\n",
        "    theta=[2.220446049250313e-16, 2.580956802971767e-08, 1.386347866119121e-05, 3.397168839976962e-04, 2.400876357887274e-03, 9.065656407595102e-03, 2.384455532500274e-02,\n",
        "         4.991228871115323e-02, 8.957760203223343e-02, 1.441829761614378e-01, 2.142358068451711e-01, 2.996158913811580e-01, 3.997775336316795e-01, 5.139146936124294e-01, 6.410835233041199e-01,\n",
        "         7.802874256626574e-01, 9.305328460786568e-01, 1.090863719290036]\n",
        "    if anorm <= theta[17]:\n",
        "      for k in (1, 2, 4, 8, 12):\n",
        "        if anorm <= theta[k]:\n",
        "          # return Taylor Polynomial of the order k\n",
        "          eA=TaylorAlgorithm(A, k, n, TILE_SIZE)\n",
        "\n",
        "    if anorm>theta[17]:\n",
        "      # find characteristic and mantissa of log2\n",
        "      value=anorm/theta[17]\n",
        "      s=0\n",
        "      while (s<=int(value)):\n",
        "          if (2**s>int(value)):\n",
        "              break\n",
        "          s+=1\n",
        "      t=2**(math.log2(value)-s)\n",
        "      if t==0.50000:\n",
        "          s=s-1\n",
        "      As=A/(2**s)\n",
        "      S=[s]\n",
        "      dev_S=cuda.to_device(S)\n",
        "      E=TaylorAlgorithm(As, 18, n, TILE_SIZE)\n",
        "      dev_E=cuda.to_device(E)\n",
        "      dev_eA=cuda.device_array([n*n,], dtype=\"complex\")\n",
        "      # blocks_per_grid=(math.ceil((n-1)/TILE_SIZE)+1, math.ceil((n-1)/TILE_SIZE)+1)\n",
        "      blocks_per_grid=(2, 2)\n",
        "      threads_per_block=(TILE_SIZE, TILE_SIZE)\n",
        "      squaring[blocks_per_grid, threads_per_block](dev_E, dev_eA, dev_S, n)\n",
        "      cuda.synchronize()\n",
        "      eA=dev_eA.copy_to_host()\n",
        "      eA=eA.reshape([n,n])\n",
        "\n",
        "    end=time.perf_counter()\n",
        "    return eA, start, end"
      ],
      "metadata": {
        "id": "CUEWKqejzSMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# possible problems\n",
        "# overscaling-high\n",
        "# inaccurate tiling size\n",
        "# implement tiling algorithm\n",
        "# driver function\n",
        "TILE_SIZE=30\n",
        "n=75\n",
        "# declaring a as a 2D array and converting to a 1D array when required (for matrix multiplication)\n",
        "a=np.zeros([n, n], dtype=\"complex\")\n",
        "for k in range(n):\n",
        "    for l in range(n):\n",
        "        a[k][l]=1+1j\n",
        "# print(a)\n",
        "eA, start, end=exponential(a, n, TILE_SIZE)\n",
        "print(eA)\n",
        "print(\"Execution Time %0.7f\" %(end-start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e90bhd0vzae7",
        "outputId": "57e2f05d-f150-4a8e-d7d9-b0e2a58c43b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-7.31489173e+41+1.58911840e+42j -6.63286771e+41+1.59094966e+42j\n",
            "   7.13315786e+37+1.19257498e+38j ...  7.81250000e-03+7.81250000e-03j\n",
            "   7.81250000e-03+7.81250000e-03j  7.81250000e-03+7.81250000e-03j]\n",
            " [ 4.48353393e+49-3.25885298e+46j  4.41458506e+49-1.63952996e+48j\n",
            "  -5.43846657e+11-3.25210574e+13j ...  7.81250000e-03+7.81250000e-03j\n",
            "   7.81250000e-03+7.81250000e-03j  7.81250000e-03+7.81250000e-03j]\n",
            " [ 3.61312021e+13+2.24187187e+13j  3.55137969e+13+2.19991058e+13j\n",
            "   1.13724757e+13+2.31346579e+13j ...  7.81250000e-03+7.81250000e-03j\n",
            "   7.81250000e-03+7.81250000e-03j  7.81250000e-03+7.81250000e-03j]\n",
            " ...\n",
            " [ 7.81250000e-03+7.81250000e-03j  7.81250000e-03+7.81250000e-03j\n",
            "   7.81250000e-03+7.81250000e-03j ...  7.81250000e-03+7.81250000e-03j\n",
            "   7.81250000e-03+7.81250000e-03j  7.81250000e-03+7.81250000e-03j]\n",
            " [ 7.81250000e-03+7.81250000e-03j  7.81250000e-03+7.81250000e-03j\n",
            "   7.81250000e-03+7.81250000e-03j ...  7.81250000e-03+7.81250000e-03j\n",
            "   7.81250000e-03+7.81250000e-03j  7.81250000e-03+7.81250000e-03j]\n",
            " [ 7.81250000e-03+7.81250000e-03j  7.81250000e-03+7.81250000e-03j\n",
            "   7.81250000e-03+7.81250000e-03j ...  7.81250000e-03+7.81250000e-03j\n",
            "   7.81250000e-03+7.81250000e-03j  7.81250000e-03+7.81250000e-03j]]\n",
            "Execution Time 0.0493953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 4 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ]
    }
  ]
}